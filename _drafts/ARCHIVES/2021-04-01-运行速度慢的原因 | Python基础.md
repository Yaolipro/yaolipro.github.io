---
layout: post
title: 运行速度慢的原因 | Python基础
category: ARCHIVES
description: 描述
tags: Python
---

Python比C、 C++执行效率低是多种原因交织在一起的原因。

我觉得关键问题是 动态类型、解释执行、虚拟机、GIL这四个方面的问题：

1、为了支持动态类型，Python对象加入了很多抽象，执行的时候要不断的判断数据类型，带来很大的开销，动态类型的动态检查开销，降低了运行速度

2、python代码由解释器逐条解释执行（interactive model）或每次执行都要先翻译再运行，运行效率大大降低。静态编译的程序在执行前全部被翻译为机器码，而解释执行的则是一句一句边运行边翻译。

3、虚拟机带来间接开销，而且Python的虚拟机cpython性也不如jvm。

4、GIL全局锁带来的伪多线程问题，所以python大力发展协程和异步语法

C++是直接编译成可执行二进制代码，有系统原生的进程、线程加持，没有动态类型的开销，没有虚拟机的开销，如果没有使用虚函数、虚继承等特性，C++代码能获得C语言一样的效率。

同样运行在虚拟机上的java，编译成字节码再执行，效率就高多了，重IO的场景与C++相比也不遑多让。

Python的另一个解释器PyPy引入了JIT、多线程等，执行效率蹭蹭的就上去了。

cpython
也就是cpython解释器太垃圾了？python官方为什么不用pypy呢

因为pypy还是很有局限性的，对于c写的库支持问题比较大。不适合所有场景。pypy牺牲了C接口兼容性

JIT
JIT编译器，英文写作Just-In-Time Compiler，中文意思是即时编译器。

JIT是一种提高程序运行效率的方法。通常，程序有两种运行方式：静态编译与动态解释。静态编译的程序在执行前全部被翻译为机器码，而解释执行的则是一句一句边运行边翻译。

## 当前GIL设计的缺陷
基于pcode数量的调度方式
按照Python社区的想法，操作系统本身的线程调度已经非常成熟稳定了，没有必要自己搞一套。所以Python的线程就是C语言的一个pthread，并通过操作系统调度算法进行调度（例如linux是CFS）。为了让各个线程能够平均利用CPU时间，python会计算当前已执行的微代码数量，达到一定阈值后就强制释放GIL。而这时也会触发一次操作系统的线程调度（当然是否真正进行上下文切换由操作系统自主决定）。

伪代码
```
while True:
    acquire GIL
    for i in 1000:
        do something
    release GIL
    /* Give Operating System a chance to do thread scheduling */
```

这种模式在只有一个CPU核心的情况下毫无问题。任何一个线程被唤起时都能成功获得到GIL（因为只有释放了GIL才会引发线程调度）。但当CPU有多个核心的时候，问题就来了。从伪代码可以看到，从release GIL到acquire GIL之间几乎是没有间隙的。所以当其他在其他核心上的线程被唤醒时，大部分情况下主线程已经又再一次获取到GIL了。这个时候被唤醒执行的线程只能白白的浪费CPU时间，看着另一个线程拿着GIL欢快的执行着。然后达到切换时间后进入待调度状态，再被唤醒，再等待，以此往复恶性循环。

PS：当然这种实现方式是原始而丑陋的，Python的每个版本中也在逐渐改进GIL和线程调度之间的互动关系。例如先尝试持有GIL在做线程上下文切换，在IO等待时释放GIL等尝试。但是无法改变的是GIL的存在使得操作系统线程调度的这个本来就昂贵的操作变得更奢侈了。 关于GIL影响的扩展阅读

为了直观的理解GIL对于多线程带来的性能影响，这里直接借用的一张测试结果图（见下图）。图中表示的是两个线程在双核CPU上得执行情况。两个线程均为CPU密集型运算线程。绿色部分表示该线程在运行，且在执行有用的计算，红色部分为线程被调度唤醒，但是无法获取GIL导致无法进行有效运算等待的时间。 


## 如何避免受到GIL的影响

说了那么多，如果不说解决方案就仅仅是个科普帖，然并卵。GIL这么烂，有没有办法绕过呢？我们来看看有哪些现成的方案。

用multiprocessing替代Thread
multiprocessing库的出现很大程度上是为了弥补thread库因为GIL而低效的缺陷。它完整的复制了一套thread所提供的接口方便迁移。唯一的不同就是它使用了多进程而不是多线程。每个进程有自己的独立的GIL，因此也不会出现进程之间的GIL争抢。

当然multiprocessing也不是万能良药。它的引入会增加程序实现时线程间数据通讯和同步的困难。就拿计数器来举例子，如果我们要多个线程累加同一个变量，对于thread来说，申明一个global变量，用thread.Lock的context包裹住三行就搞定了。而multiprocessing由于进程之间无法看到对方的数据，只能通过在主线程申明一个Queue，put再get或者用share memory的方法。这个额外的实现成本使得本来就非常痛苦的多线程程序编码，变得更加痛苦了。具体难点在哪有兴趣的读者可以扩展阅读这篇文章

用其他解析器
之前也提到了既然GIL只是CPython的产物，那么其他解析器是不是更好呢？没错，像JPython和IronPython这样的解析器由于实现语言的特性，他们不需要GIL的帮助。然而由于用了Java/C#用于解析器实现，他们也失去了利用社区众多C语言模块有用特性的机会。所以这些解析器也因此一直都比较小众。毕竟功能和性能大家在初期都会选择前者，Done is better than perfect。

所以没救了么？
当然Python社区也在非常努力的不断改进GIL，甚至是尝试去除GIL。并在各个小版本中有了不少的进步。有兴趣的读者可以扩展阅读这个Slide 另一个改进Reworking the GIL

将切换颗粒度从基于opcode计数改成基于时间片计数

避免最近一次释放GIL锁的线程再次被立即调度

新增线程优先级功能（高优先级线程可以迫使其他线程释放所持有的GIL锁）

总结
Python GIL其实是功能和性能之间权衡后的产物，它尤其存在的合理性，也有较难改变的客观因素。从本分的分析中，我们可以做以下一些简单的总结：

因为GIL的存在，只有IO Bound场景下得多线程会得到较好的性能

如果对并行计算性能较高的程序可以考虑把核心部分也成C模块，或者索性用其他语言实现

GIL在较长一段时间内将会继续存在，但是会不断对其进行改进

Reference

* https://wiki.python.org/moin/GlobalInterpreterLock
* http://www.dabeaz.com/GIL/